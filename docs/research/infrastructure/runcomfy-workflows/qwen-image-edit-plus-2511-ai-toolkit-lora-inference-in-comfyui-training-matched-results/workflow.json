{
  "id": "00000000-0000-0000-0000-000000000000",
  "extra": {
    "ds": {
      "scale": 1,
      "offset": [
        -285.62644958496094,
        111.57833862304688
      ]
    },
    "reroutes": null,
    "frontendVersion": "1.36.14",
    "workflowRendererVersion": "LG"
  },
  "links": [
    [
      3,
      0,
      0,
      1,
      0,
      "IMAGE"
    ],
    [
      4,
      1,
      0,
      2,
      0,
      "IMAGE"
    ]
  ],
  "nodes": [
    {
      "id": 2,
      "pos": [
        982.798828125,
        130
      ],
      "mode": 0,
      "size": [
        270,
        270
      ],
      "type": "SaveImage",
      "flags": {},
      "order": 3,
      "inputs": [
        {
          "dir": null,
          "pos": null,
          "link": 4,
          "name": "images",
          "type": "IMAGE",
          "label": null,
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null
        }
      ],
      "outputs": [],
      "properties": {
        "ver": "0.9.1",
        "cnr_id": "comfy-core"
      },
      "showAdvanced": null,
      "widgets_values": [
        "rc_qwen_image_edit_plus_2511"
      ]
    },
    {
      "id": 0,
      "pos": [
        100,
        130
      ],
      "mode": 0,
      "size": [
        282.798828125,
        314
      ],
      "type": "LoadImage",
      "flags": {},
      "order": 0,
      "inputs": [],
      "outputs": [
        {
          "dir": null,
          "pos": null,
          "name": "IMAGE",
          "type": "IMAGE",
          "label": null,
          "links": [
            3
          ],
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null,
          "slot_index": null
        },
        {
          "dir": null,
          "pos": null,
          "name": "MASK",
          "type": "MASK",
          "label": null,
          "links": null,
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null,
          "slot_index": null
        }
      ],
      "properties": {
        "ver": "0.9.1",
        "cnr_id": "comfy-core",
        "Node name for S&R": "LoadImage"
      },
      "showAdvanced": null,
      "widgets_values": [
        "01.png",
        "image"
      ]
    },
    {
      "id": 3,
      "pos": [
        -560.538330078125,
        108.57705688476562
      ],
      "mode": 0,
      "size": [
        613.617919921875,
        723.728759765625
      ],
      "type": "MarkdownNote",
      "color": "#432",
      "flags": {},
      "order": 1,
      "inputs": [],
      "bgcolor": "#653",
      "outputs": [],
      "properties": {},
      "showAdvanced": null,
      "widgets_values": [
        "## Workflow Notes Â· Using Your Trained LoRA\n\nThis workflow supports **three equivalent ways** to load a LoRA.  \nChoose **one** based on where your LoRA file comes from.\n\n---\n\n### 1. Get the LoRA path and load it into the workflow\n\n#### **Option A Â· RunComfy training result (recommended)**\nUse this if the LoRA was trained on RunComfy.\n\n- Go to **[RunComfy â†’ Trainer â†’ LoRA Assets](https://www.runcomfy.com/trainer/lora-assets)**  \n- Find the LoRA you want to use  \n- Click the ðŸ‘‰ **â‹® (three-dot)** menu on the right  \n- Select **Copy LoRA Link**  \n- Paste the copied URL into this workflowâ€™s custom node field: **`lora_path`**\n\nThis method uses the **cloud LoRA asset** directly â€” no local files required.\n\n---\n\n#### **Option B Â· AI Toolkit LoRA trained outside RunComfy**\n\n- Copy the **direct `.safetensors` download URL** of your LoRA file, then paste it **directly into `lora_path`** in the **RC QwenImageEditPlus2511** node.\n\n- The **RC QwenImageEditPlus2511** node will automatically fetch and load the LoRA at runtime â€” there is **no need to manually download the file** or place it into `ComfyUI/models/loras`.\n\n- Tip: Make sure the link points to the actual `.safetensors` file (not a web page or redirect).\n\n---\n\n### 2. Match inference parameters with your training sample settings\n\nIf you customized any values during training (for example):\n\n- `seed`\n- `guidance_scale`\n- `trigger_words`\n- `sample_steps`\n\nmake sure the corresponding nodes in this workflow use the **same values**.\n\n> **Note**  \n> If you did **not** customize sample parameters during training, you can keep the current workflow defaults.  \n> If you trained this LoRA on RunComfy, you can find your YAML config easily on the **[LoRA Assets](https://www.runcomfy.com/trainer/lora-assets)** page.\n\n---\n\n### Quick checklist\n\n- âœ… `lora_path` points to a **directly downloadable `.safetensors` file** generated by **AI Toolkit training** (RunComfy LoRA link or an equivalent direct file URL)  \n- âœ… Inference parameters match training **`sample`** config (if customized)\n\nIf all three are correct, what you see here should closely match what you saw during training previews.\n"
      ]
    },
    {
      "id": 1,
      "pos": [
        482.798828125,
        130
      ],
      "mode": 0,
      "size": [
        400,
        398
      ],
      "type": "RCQwenImageEditPlus2511",
      "flags": {},
      "order": 2,
      "inputs": [
        {
          "dir": null,
          "pos": null,
          "link": 3,
          "name": "control_image",
          "type": "IMAGE",
          "label": null,
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null
        },
        {
          "dir": null,
          "pos": null,
          "link": null,
          "name": "control_image_2",
          "type": "IMAGE",
          "label": null,
          "shape": 7,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null
        },
        {
          "dir": null,
          "pos": null,
          "link": null,
          "name": "control_image_3",
          "type": "IMAGE",
          "label": null,
          "shape": 7,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null
        }
      ],
      "outputs": [
        {
          "dir": null,
          "pos": null,
          "name": "image",
          "type": "IMAGE",
          "label": null,
          "links": [
            4
          ],
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null,
          "slot_index": null
        }
      ],
      "properties": {
        "ver": "860c5976908e0c602299a0ad9e12e56ac58ca04c",
        "aux_id": "runcomfy-com/ai-toolkit-inference",
        "Node name for S&R": "RCQwenImageEditPlus2511"
      },
      "showAdvanced": null,
      "widgets_values": [
        "a woman standing in front of the desk",
        1024,
        1024,
        25,
        4,
        42,
        "fixed",
        "https://trainers-storage.runcomfy.net/trainers/STUgcgyFf5avXwCU/qwen_edit_2511_000000500.safetensors",
        1,
        "",
        ""
      ]
    }
  ],
  "config": {},
  "groups": [],
  "version": 0.4,
  "revision": 0,
  "definitions": null,
  "last_link_id": 4,
  "last_node_id": 3,
  "floatingLinks": null
}