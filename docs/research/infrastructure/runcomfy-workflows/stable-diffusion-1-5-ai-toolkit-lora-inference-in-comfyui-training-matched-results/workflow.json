{
  "id": "00000000-0000-0000-0000-000000000000",
  "extra": {
    "ds": {
      "scale": 0.9090909090909091,
      "offset": [
        707.1330457427766,
        174.50004442320935
      ]
    },
    "reroutes": null,
    "frontendVersion": "1.36.14",
    "workflowRendererVersion": "LG"
  },
  "links": [
    [
      3,
      4,
      0,
      2,
      0,
      "IMAGE"
    ]
  ],
  "nodes": [
    {
      "id": 3,
      "pos": [
        -392.6727294921875,
        112.96615600585938
      ],
      "mode": 0,
      "size": [
        439.1746826171875,
        679.193359375
      ],
      "type": "MarkdownNote",
      "color": "#432",
      "flags": {},
      "order": 0,
      "inputs": [],
      "bgcolor": "#653",
      "outputs": [],
      "properties": {},
      "showAdvanced": null,
      "widgets_values": [
        "## Workflow Notes Â· Using Your Trained LoRA\n\nThis workflow supports **three equivalent ways** to load a LoRA.  \nChoose **one** based on where your LoRA file comes from.\n\n---\n\n### 1. Get the LoRA path and load it into the workflow\n\n#### **Option A Â· RunComfy training result (recommended)**\nUse this if the LoRA was trained on RunComfy.\n\n- Go to **[RunComfy â†’ Trainer â†’ LoRA Assets](https://www.runcomfy.com/trainer/lora-assets)**  \n- Find the LoRA you want to use  \n- Click the ðŸ‘‰ **â‹® (three-dot)** menu on the right  \n- Select **Copy LoRA Link**  \n- Paste the copied URL into this workflowâ€™s custom node field: **`lora_path`**\n\nThis method uses the **cloud LoRA asset** directly â€” no local files required.\n\n---\n\n#### **Option B Â· AI Toolkit LoRA trained outside RunComfy**\n\n- Copy the **direct `.safetensors` download URL** of your LoRA file, then paste it **directly into `lora_path`** in the **RC SD 1.5** node.\n\n- The **RC SD 1.5** node will automatically fetch and load the LoRA at runtime â€” there is **no need to manually download the file** or place it into `ComfyUI/models/loras`.\n\n- Tip: Make sure the link points to the actual `.safetensors` file (not a web page or redirect).\n\n---\n\n### 2. Match inference parameters with your training sample settings\n\nIf you customized any values during training (for example):\n\n- `seed`\n- `guidance_scale`\n- `trigger_words`\n- `sample_steps`\n\nmake sure the corresponding nodes in this workflow use the **same values**.\n\n> **Note**  \n> If you did **not** customize sample parameters during training, you can keep the current workflow defaults.  \n> If you trained this LoRA on RunComfy, you can find your YAML config easily on the **[LoRA Assets](https://www.runcomfy.com/trainer/lora-assets)** page.\n\n---\n\n### Quick checklist\n\n- âœ… `lora_path` points to a **directly downloadable `.safetensors` file** generated by **AI Toolkit training** (RunComfy LoRA link or an equivalent direct file URL)  \n- âœ… Inference parameters match training **`sample`** config (if customized)\n\nIf all three are correct, what you see here should closely match what you saw during training previews.\n"
      ]
    },
    {
      "id": 2,
      "pos": [
        600,
        130
      ],
      "mode": 0,
      "size": [
        270,
        270
      ],
      "type": "SaveImage",
      "flags": {},
      "order": 2,
      "inputs": [
        {
          "dir": null,
          "pos": null,
          "link": 3,
          "name": "images",
          "type": "IMAGE",
          "label": null,
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null
        }
      ],
      "outputs": [],
      "properties": {
        "ver": "0.9.1",
        "cnr_id": "comfy-core"
      },
      "showAdvanced": null,
      "widgets_values": [
        "rc_sd15"
      ]
    },
    {
      "id": 4,
      "pos": [
        111.01632559511428,
        136.36373884095133
      ],
      "mode": 0,
      "size": [
        400,
        358
      ],
      "type": "RCSD15",
      "flags": {},
      "order": 1,
      "inputs": [],
      "outputs": [
        {
          "dir": null,
          "pos": null,
          "name": "image",
          "type": "IMAGE",
          "label": null,
          "links": [
            3
          ],
          "shape": null,
          "locked": null,
          "color_on": null,
          "color_off": null,
          "removable": null,
          "nameLocked": null,
          "slot_index": null
        }
      ],
      "properties": {
        "ver": "baee702195ad3747c1ab331cf97cba0728c12a8f",
        "aux_id": "runcomfy-com/ai-toolkit-inference",
        "Node name for S&R": "RCSD15"
      },
      "showAdvanced": null,
      "widgets_values": [
        "SD15 a woman holding a coffee cup, in a beanie, sitting at a cafe",
        1024,
        1024,
        25,
        6,
        42,
        "fixed",
        "https://trainers-storage.runcomfy.net/trainers/mJOIr1hZGwpu4X4G/sd_15_000000500.safetensors",
        1,
        "",
        ""
      ]
    }
  ],
  "config": {},
  "groups": [],
  "version": 0.4,
  "revision": 0,
  "definitions": null,
  "last_link_id": 3,
  "last_node_id": 4,
  "floatingLinks": null
}