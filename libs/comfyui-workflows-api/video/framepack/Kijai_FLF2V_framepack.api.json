{
  "12": {
    "inputs": {
      "vae_name": "hunyuan_video_vae_bf16.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "13": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "llava_llama3_fp16.safetensors",
      "type": "hunyuan_video",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "15": {
    "inputs": {
      "conditioning": [
        "47",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "17": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "18",
        0
      ],
      "image": [
        "48",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "18": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "19": {
    "inputs": {
      "image": "input-1.webp"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "20": {
    "inputs": {
      "pixels": [
        "48",
        0
      ],
      "vae": [
        "12",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "33": {
    "inputs": {
      "tile_size": 256,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": [
        "39",
        0
      ],
      "vae": [
        "12",
        0
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "39": {
    "inputs": {
      "model": [
        "52",
        0
      ],
      "positive": [
        "47",
        0
      ],
      "negative": [
        "15",
        0
      ],
      "image_embeds": [
        "17",
        0
      ],
      "start_latent": [
        "20",
        0
      ],
      "end_latent": [
        "64",
        0
      ],
      "end_image_embeds": [
        "63",
        0
      ]
    },
    "class_type": "FramePackSampler",
    "_meta": {
      "title": "FramePackSampler"
    }
  },
  "47": {
    "inputs": {
      "text": "The girl spins dramatically, her braid whipping through the air as her dress flows with the motion.",
      "clip": [
        "13",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "48": {
    "inputs": {
      "image": [
        "50",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "50": {
    "inputs": {
      "image": [
        "19",
        0
      ],
      "width": [
        "51",
        0
      ],
      "height": [
        "51",
        1
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ImageResize+"
    }
  },
  "51": {
    "inputs": {
      "image": [
        "19",
        0
      ]
    },
    "class_type": "FramePackFindNearestBucket",
    "_meta": {
      "title": "FramePackFindNearestBucket"
    }
  },
  "52": {
    "inputs": {},
    "class_type": "LoadFramePackModel",
    "_meta": {
      "title": "LoadFramePackModel"
    }
  },
  "59": {
    "inputs": {
      "image": "input-2.webp"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "60": {
    "inputs": {
      "image": [
        "59",
        0
      ],
      "width": [
        "61",
        0
      ],
      "height": [
        "61",
        1
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ImageResize+"
    }
  },
  "61": {
    "inputs": {
      "image": [
        "59",
        0
      ]
    },
    "class_type": "FramePackFindNearestBucket",
    "_meta": {
      "title": "FramePackFindNearestBucket"
    }
  },
  "62": {
    "inputs": {
      "image": [
        "60",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "63": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "18",
        0
      ],
      "image": [
        "62",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "64": {
    "inputs": {
      "pixels": [
        "62",
        0
      ],
      "vae": [
        "12",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  }
}